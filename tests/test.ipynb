{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3185, 0.5773, 0.3334],\n",
       "        [0.5209, 0.9920, 0.7909]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.3185, 0.5773, 0.3334]), tensor([0.5209, 0.9920, 0.7909])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3185, 0.5773, 0.3334, 0.5209, 0.9920, 0.7909])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([*a], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch src: [['how', 'are', 'you'], ['goodbye']]\n",
      "Batch tgt: [['你', '好吗'], ['再见']]\n",
      "Batch src: [['I', 'am', 'fine'], ['hello', 'world']]\n",
      "Batch tgt: [['我', '很好'], ['你好', '世界']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 定义一个简单的数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "# 自定义 collate_fn\n",
    "def my_collate_fn(batch):\n",
    "    # 将批次数据按源句子长度排序\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    \n",
    "    # 分离源句子和目标句子\n",
    "    src_sents = [item[0] for item in batch]\n",
    "    tgt_sents = [item[1] for item in batch]\n",
    "    \n",
    "    # 根据需要转换成张量\n",
    "    # src_sents = [torch.tensor(sent) for sent in src_sents]\n",
    "    # tgt_sents = [torch.tensor(sent) for sent in tgt_sents]\n",
    "    \n",
    "    return src_sents, tgt_sents\n",
    "\n",
    "# 示例数据\n",
    "data = [(['hello', 'world'], ['你好', '世界']),\n",
    "        (['goodbye'], ['再见']),\n",
    "        (['how', 'are', 'you'], ['你', '好吗']),\n",
    "        (['I', 'am', 'fine'], ['我', '很好'])]\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = MyDataset(data)\n",
    "\n",
    "# 创建 DataLoader 实例，传入自定义的 collate_fn\n",
    "data_loader = DataLoader(dataset, batch_size=2, collate_fn=my_collate_fn, shuffle=True)\n",
    "\n",
    "# 迭代 DataLoader 并查看输出\n",
    "for batch_src, batch_tgt in data_loader:\n",
    "    print('Batch src:', batch_src)\n",
    "    print('Batch tgt:', batch_tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "def compute_ngram(sentence, n: int):\n",
    "    counter = Counter()\n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        counter[tuple(sentence[i: i + n])] += 1\n",
    "    return counter\n",
    "\n",
    "def compute_blue(candidate, references: List[str], weight=[0.25] * 4):\n",
    "    assert sum(weight) == 1, \"Weights must sum up to 1\"\n",
    "    \n",
    "    # Compute modified precision for n=1 to 4\n",
    "    p = []\n",
    "    for i in range(4):\n",
    "        candidate_counter = compute_ngram(candidate.split(), n=i+1)\n",
    "        ref_counters = [compute_ngram(sent.split(), n=i+1) for sent in references]\n",
    "        \n",
    "        numerator = 0\n",
    "        for n_gram in candidate_counter:\n",
    "            count = candidate_counter[n_gram]\n",
    "            max_ref_count = max(ref_counter[n_gram] for ref_counter in ref_counters)\n",
    "            numerator += min(max_ref_count, count)\n",
    "        \n",
    "        denominator = sum(candidate_counter.values())\n",
    "        p_i = numerator / denominator if denominator != 0 else 0\n",
    "        p.append(p_i)\n",
    "    \n",
    "    # Compute brevity penalty\n",
    "    len_candidate = len(candidate.split())\n",
    "    reference_lengths = [len(ref.split()) for ref in references]\n",
    "    closest_ref_len = min(reference_lengths,\n",
    "                          key=lambda ref_len: (abs(ref_len - len_candidate), ref_len))\n",
    "    if len_candidate > closest_ref_len:\n",
    "        BP = 1\n",
    "    else:\n",
    "        BP = math.exp(1 - closest_ref_len / len_candidate) if len_candidate != 0 else 0\n",
    "    print(BP)\n",
    "    \n",
    "    # Compute BLEU score\n",
    "    if min(p) > 0:\n",
    "        bleu_score = BP * math.exp(sum(weight[i] * math.log(p[i]) for i in range(4)))\n",
    "    else:\n",
    "        bleu_score = 0\n",
    "    \n",
    "    return bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6065306597126334\n",
      "Custom BLEU: 0.6065\n",
      "NLTK BLEU: 0.6065\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def test_compute_blue():\n",
    "    candidate = \"I am Muqi Li\"\n",
    "    references = [\"I am Muqi Li hello world\"]\n",
    "    \n",
    "    # Custom BLEU calculation\n",
    "    blue_score = compute_blue(candidate, references)\n",
    "    \n",
    "    # NLTK BLEU calculation\n",
    "    candidate_tokens = candidate.split()\n",
    "    reference_tokens = [ref.split() for ref in references]\n",
    "    nltk_bleu_score = sentence_bleu(reference_tokens, candidate_tokens)\n",
    "    \n",
    "    print(f\"Custom BLEU: {blue_score:.4f}\")\n",
    "    print(f\"NLTK BLEU: {nltk_bleu_score:.4f}\")\n",
    "\n",
    "test_compute_blue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(200, embedding_dim=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3933,  0.2923,  1.0104,  0.7737, -0.0134, -2.3021, -0.1026, -1.4181,\n",
       "          0.2057, -0.5339,  0.7247,  2.0076],\n",
       "        [ 0.6525,  1.5984,  0.3935, -1.4660, -0.3545,  1.0624, -1.2419, -0.3716,\n",
       "         -1.1960,  0.4022,  0.3508, -0.6016]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(torch.LongTensor([12, 21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([12, 21]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
